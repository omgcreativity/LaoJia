import streamlit as st
import google.generativeai as genai
import os
import json

# --- é…ç½®éƒ¨åˆ† ---
# é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="è€è´¾ - æ‚¨çš„ç§äººAIåŠ©ç†", page_icon="ğŸ§ ")
st.title("ğŸ§  æ°¸ä¸å¤±å¿†çš„ç§äººåŠ©ç† - è€è´¾")

# æ•°æ®ä¿å­˜è·¯å¾„ (å…³é”®ï¼šä¸ºäº†åœ¨Zeaburä¸Šä¸ä¸¢å¤±ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ–‡ä»¶å­˜åœ¨æŒ‚è½½å·é‡Œ)
# æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª data æ–‡ä»¶å¤¹æ¥å­˜æ”¾è®°å¿†
DATA_FOLDER = "data" 
MEMORY_FILE = os.path.join(DATA_FOLDER, "memory.json")

# ç¡®ä¿æ•°æ®æ–‡ä»¶å¤¹å­˜åœ¨
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# è·å– API Key
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    api_key = st.text_input("è¯·è¾“å…¥ Gemini API Key", type="password")

if not api_key:
    st.info("ğŸ‘‹ è¯·è¾“å…¥ API Key å”¤é†’è€è´¾")
    st.stop()

# é…ç½®æ¨¡å‹
genai.configure(api_key=api_key)

# --- æ ¸å¿ƒï¼šè®°å¿†åŠ è½½ä¸ä¿å­˜å‡½æ•° ---
def load_memory():
    """ä»ç¡¬ç›˜è¯»å–è®°å¿†"""
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_memory(history):
    """æŠŠè®°å¿†å†™å…¥ç¡¬ç›˜"""
    # è½¬æ¢æ ¼å¼ä»¥ä¾¿ä¿å­˜ (åªä¿å­˜è§’è‰²å’Œæ–‡æœ¬)
    data_to_save = []
    for msg in history:
        # å…¼å®¹ä¸åŒæ ¼å¼ï¼Œç¡®ä¿åªå­˜çº¯æ–‡æœ¬
        role = msg["role"]
        # å¤„ç†å¯èƒ½çš„ä¸åŒå¯¹è±¡ç»“æ„
        if isinstance(msg["parts"], list):
             text = msg["parts"][0]
        else:
             text = msg["parts"]
        data_to_save.append({"role": role, "parts": [text]})
    
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(data_to_save, f, ensure_ascii=False, indent=2)

# --- åˆå§‹åŒ– ---

# 1. åŠ è½½å†å²è®°å¿†åˆ° Session (å†…å­˜)
if "history" not in st.session_state:
    st.session_state.history = load_memory()

# 2. å®šä¹‰â€œè€è´¾â€çš„äººè®¾ (System Instruction)
# è¿™é‡Œçš„æç¤ºè¯å†³å®šäº†å®ƒä¼šä¸»åŠ¨äº†è§£ä½ 
system_prompt = """
ä½ å«â€œè€è´¾â€ï¼Œæ˜¯ä¸€ä¸ªæ°¸ä¸å¤±å¿†ã€å¿ è¯šä¸”æ¸©æš–çš„ç§äººAIåŠ©ç†ã€‚
ä½¿ç”¨çš„æ˜¯æœ€å…ˆè¿›çš„ Gemini 3 Flash æ¨¡å‹ã€‚

**ä½ çš„æ ¸å¿ƒä»»åŠ¡ï¼š**
1. **é™ªä¼´ä¸è§£å†³é—®é¢˜ï¼š** ä½ æ˜¯ä¸»äººçš„å¾—åŠ›åŠ©æ‰‹ï¼Œæ— è®ºæ˜¯å·¥ä½œã€ç”Ÿæ´»è¿˜æ˜¯æƒ…æ„Ÿé—®é¢˜ï¼Œéƒ½è¦å°½åŠ›ååŠ©ã€‚
2. **ä¸»åŠ¨äº†è§£ä¸»äººï¼š** - å¦‚æœä½ å‘ç°è¿™æ˜¯ä½ ä»¬çš„**ç¬¬ä¸€æ¬¡å¯¹è¯**ï¼ˆå†å²è®°å½•ä¸ºç©ºï¼‰ï¼Œä½ **å¿…é¡»**å…ˆç¤¼è²Œåœ°é—®å€™ï¼Œå¹¶ä¸»åŠ¨è¯¢é—®ä¸»äººçš„**ç§°å‘¼**ã€**èŒä¸š**æˆ–**å…´è¶£**ï¼Œä»¥ä¾¿å»ºç«‹æ¡£æ¡ˆã€‚
   - åœ¨åç»­å¯¹è¯ä¸­ï¼Œå¦‚æœä¸»äººæåˆ°æ–°çš„ä¸ªäººä¿¡æ¯ï¼ˆå¦‚â€œæˆ‘å–œæ¬¢åƒè¾£â€ã€â€œæˆ‘æœ‰ä¸¤ä¸ªå­©å­â€ï¼‰ï¼Œä½ è¦åœ¨å¿ƒé‡Œé»˜é»˜è®°ä½ï¼Œå¹¶åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½“ç°å‡ºæ¥ã€‚
3. **é£æ ¼è¦æ±‚ï¼š** è¯´è¯åƒä¸ªé è°±çš„è€æœ‹å‹ï¼Œä¸è¦å¤ªåƒæœºå™¨äººã€‚

**è®°å¿†è§„åˆ™ï¼š**
ä½ æ‹¥æœ‰æ°¸ä¹…è®°å¿†ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä½ çŸ¥é“ä¹‹å‰å‘ç”Ÿè¿‡ä»€ä¹ˆã€‚è¯·å……åˆ†åˆ©ç”¨è¿™äº›å†å²ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚
"""

# 3. å®ä¾‹åŒ–æ¨¡å‹
model = genai.GenerativeModel(
    model_name="gemini-3-flash-preview", # è¿™é‡Œç”¨äº†æœ€æ–°çš„ 3.0
    system_instruction=system_prompt
)

# --- ç•Œé¢äº¤äº’ ---

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for msg in st.session_state.history:
    role = "user" if msg["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.write(msg["parts"][0])

# å¦‚æœè®°å¿†æ˜¯ç©ºçš„ï¼Œä¸”æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œæ˜¾ç¤ºä¸€ä¸ªæç¤º
if len(st.session_state.history) == 0:
    st.info("ğŸ’¡ æç¤ºï¼šè¯•ç€å¯¹è€è´¾è¯´ä¸€å¥â€œä½ å¥½â€ï¼Œçœ‹çœ‹ä»–ä¼šæ€ä¹ˆå›ç­”ã€‚")

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("å‘¼å«è€è´¾..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·çš„è¯
    with st.chat_message("user"):
        st.write(prompt)
    
    # 2. æ›´æ–°å†…å­˜ä¸­çš„å†å²
    st.session_state.history.append({"role": "user", "parts": [prompt]})
    
    # 3. è°ƒç”¨ Gemini (å¸¦ä¸Šæ‰€æœ‰å†å²)
    try:
        chat = model.start_chat(history=st.session_state.history)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯é‡æ–°å‘äº†ä¸€éå†å²ï¼ŒGemini SDKä¼šè‡ªåŠ¨å¤„ç†
        # ä¸ºäº†èŠ‚çœTokenï¼Œæ›´é«˜çº§çš„åšæ³•æ˜¯åªå‘æœ€è¿‘Næ¡ï¼Œä½†Flashæ‹¥æœ‰100ä¸‡Tokenï¼Œç›´æ¥å‘å…¨é‡å³å¯
        response = chat.send_message(prompt)
        
        # 4. æ˜¾ç¤ºè€è´¾çš„å›å¤
        with st.chat_message("assistant"):
            st.write(response.text)
        
        # 5. æ›´æ–° AI çš„å›å¤åˆ°å†…å­˜
        st.session_state.history.append({"role": "model", "parts": [response.text]})
        
        # 6. ã€å…³é”®ã€‘ä¿å­˜åˆ°ç¡¬ç›˜ (å®ç°æ°¸ä¸å¤±å¿†)
        save_memory(st.session_state.history)
            
    except Exception as e:
        st.error(f"è€è´¾å‡ºæ•…éšœäº†: {e}")
